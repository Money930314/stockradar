import feedparser, html
from urllib.parse import quote_plus, urlparse
from telegram import Update
from telegram.ext import ContextTypes

__all__ = ["news_cmd"]

GOOGLE_NEWS = "https://news.google.com/rss/search?q="

# ----------------- helpers -----------------

def _dedup(items: list[tuple[str, str]]) -> list[tuple[str, str]]:
    seen = set(); uniq = []
    for title, link in items:
        if (title, link) not in seen:
            seen.add((title, link)); uniq.append((title, link))
    return uniq


def _fetch_google(keyword: str, site: str | None = None, max_items: int = 10):
    q = quote_plus(keyword)
    if site:
        q += f"+site:{site}"
    url = f"{GOOGLE_NEWS}{q}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    feed = feedparser.parse(url)
    return [(e.title, e.link) for e in feed.entries[:max_items]]


def _domain(link: str) -> str:
    netloc = urlparse(link).netloc.lower()
    if netloc.startswith("www."):
        netloc = netloc[4:]
    return netloc.split(":" )[0]  # å»æ‰å¯èƒ½çš„ :443


def _format_links(hits: list[tuple[str, str]], icon: str) -> str:
    """ç”¢ç”Ÿã€emoji + å¯é»æ¨™é¡Œ (ä¾†æº)ã€æ ¼å¼ï¼Œæ¯æ¢ä»¥ç©ºè¡Œåˆ†éš”"""
    lines = []
    for idx, (title, link) in enumerate(hits, 1):
        source = _domain(link)
        safe_title = html.escape(title)
        safe_link  = html.escape(link, quote=True)
        lines.append(f"{idx}. {icon} <a href=\"{safe_link}\">{safe_title}</a> ({source})")
    return "\n\n".join(lines)

# ----------------- /news ä¸»æŒ‡ä»¤ -----------------

async def news_cmd(u: Update, c: ContextTypes.DEFAULT_TYPE):
    if not c.args:
        return await u.message.reply_text(
            "ç”¨æ³•ï¼š\n/news industry <é—œéµå­—>\n/news policy <é—œéµå­—>")

    cat = c.args[0].lower()
    kw  = " ".join(c.args[1:]).strip() or "å¸‚å ´"

    # -------- industry --------
    if cat == "industry":
        hits = _dedup(
            _fetch_google(kw, None, 10) +
            _fetch_google(kw, "cnn.com", 5) +
            _fetch_google(kw, "wsj.com", 5)
        )
        if not hits:
            return await u.message.reply_text("âŒ æœªèƒ½å–å¾—ä»»ä½•æ–°èçµæœ")
        msg = _format_links(hits[:10], "ğŸ“°")
        return await u.message.reply_text(msg, parse_mode="HTML", disable_web_page_preview=True)

    # -------- policy --------
    if cat == "policy":
        base_kw = kw or "å¤®è¡Œ å‡æ¯"
        hits = _dedup(
            _fetch_google(base_kw, "federalreserve.gov", 5) +
            _fetch_google(base_kw, "cbc.gov.tw", 5) +
            _fetch_google(base_kw, "twse.com.tw", 5) or
            _fetch_google(base_kw, None, 10)
        )
        if not hits:
            return await u.message.reply_text("âŒ æœªèƒ½å–å¾—ä»»ä½•æ”¿ç­–æ–°è")
        msg = _format_links(hits[:10], "ğŸ›ï¸")
        return await u.message.reply_text(msg, parse_mode="HTML", disable_web_page_preview=True)

    return await u.message.reply_text("åˆ†é¡è«‹ç”¨ industry æˆ– policyï¼Œä¾‹å¦‚ï¼š/news industry AI")
